{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respective-irish",
   "metadata": {},
   "source": [
    "- **What is pickling/unpickling?**\n",
    "\n",
    "Python library offers a feature - serialization out of the box. Serializing a object refers to transforming it into a format that can be stored, so as to be able to deserialize it later on, to obtain the original object. Here, the pickle module comes into play.\n",
    "\n",
    "**Pickling** is the name of the serialization process in Python. Any object in Python can be serialized into a byte stream and dumped as a file in the memory. The process of pickling is compact but pickle objects can be compressed further. Moreover, pickle keeps track of the objects it has serialized and the serialization is portable across versions.\n",
    "The function used for the above process is `pickle.dump()`.\n",
    "\n",
    "**Unpickling** is the complete inverse of pickling. It deserializes the byte stream to recreate the objects stored in the file, and loads the object to memory.\n",
    "The function used for the above process is `pickle.load()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-medicine",
   "metadata": {},
   "source": [
    "- **What is `__dict__` method?**\n",
    "\n",
    "\n",
    "`__dict__` is A dictionary or other mapping object used to store an object’s (writable) attributes.\n",
    "Or speaking in simple words every object in python has an attribute which is denoted by `__dict__`.\n",
    "And this object contains all attributes defined for the object. `__dict__` is also called `mappingproxy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__repr__': <slot wrapper '__repr__' of 'bool' objects>,\n",
       "              '__and__': <slot wrapper '__and__' of 'bool' objects>,\n",
       "              '__rand__': <slot wrapper '__rand__' of 'bool' objects>,\n",
       "              '__xor__': <slot wrapper '__xor__' of 'bool' objects>,\n",
       "              '__rxor__': <slot wrapper '__rxor__' of 'bool' objects>,\n",
       "              '__or__': <slot wrapper '__or__' of 'bool' objects>,\n",
       "              '__ror__': <slot wrapper '__ror__' of 'bool' objects>,\n",
       "              '__new__': <function bool.__new__(*args, **kwargs)>,\n",
       "              '__doc__': 'bool(x) -> bool\\n\\nReturns True when the argument x is true, False otherwise.\\nThe builtins True and False are the only two instances of the class bool.\\nThe class bool is a subclass of the class int, and cannot be subclassed.'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-louis",
   "metadata": {},
   "source": [
    "- **What are** `*args` **and** `**kwargs` **?**\n",
    "\n",
    "Given a function defined as the following\n",
    "\n",
    "```\n",
    "def a_function(*args,**kwargs):\n",
    "    #some code\n",
    "```\n",
    "\n",
    "`args` is a tuple for the positional arguments, and `kwargs` a dictionary for the keyword arguments. * unpacks a tuple and ** a dictionary.\n",
    "`*args` (positional arguments) always comes before `**kwargs` (keyword arguments)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-working",
   "metadata": {},
   "source": [
    "- **What is `__init__.py` for in a Python source directory?** \n",
    "\n",
    "A regular package is typically implemented as a directory containing an `__init__.py` file. When a regular package is imported, this `__init__.py` file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The `__init__.py` file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.\n",
    "\n",
    "For example, the following file system layout defines a top level parent package with three subpackages:\n",
    "```\n",
    "parent/\n",
    "    __init__.py\n",
    "    one/\n",
    "        __init__.py\n",
    "    two/\n",
    "        __init__.py\n",
    "    three/\n",
    "        __init__.py\n",
    "```\n",
    "\n",
    "Importing `parent.one` will implicitly execute `parent/__init__.py` and `parent/one/__init__.py`. Subsequent imports of `parent.two` or `parent.three` will execute `parent/two/__init__.py` and `parent/three/__init__.py` respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-timing",
   "metadata": {},
   "source": [
    "\n",
    "- **Meaning of `@classmethod` and `@staticmethod` in python?**\n",
    "\n",
    "`@staticmethod` function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It’s definition is immutable via inheritance.\n",
    "\n",
    "`@classmethod` function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That’s because the first argument for `@classmethod` function must always be `cls` (class).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "patent-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Date(object):\n",
    "\n",
    "    def __init__(self, day=0, month=0, year=0):\n",
    "        self.day = day\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, date_as_string):\n",
    "        day, month, year = map(int, date_as_string.split('-'))\n",
    "        date1 = cls(day, month, year)\n",
    "        return date1\n",
    "\n",
    "    @staticmethod\n",
    "    def is_date_valid(date_as_string):\n",
    "        day, month, year = map(int, date_as_string.split('-'))\n",
    "        return day <= 31 and month <= 12 and year <= 3999\n",
    "\n",
    "date2 = Date.from_string('11-09-2012')\n",
    "is_date = Date.is_date_valid('11-09-2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "great-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Date at 0x201735174f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date2 = Date.from_string('11-09-2012')\n",
    "date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forced-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date.is_date_valid('11-09-2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-alliance",
   "metadata": {},
   "source": [
    "- **How can the ternary operators be used in python?**\n",
    "\n",
    "[on_true] if [expression] else [on_false]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-candidate",
   "metadata": {},
   "source": [
    "- **Data preprocessing before spliting in train/test samples is a good praxis?**\n",
    "\n",
    "We must be careful with **Data Leakage**, that is when information from outside the training dataset is used to create the model and hence can lead to predictions too optimistic.\n",
    "\n",
    "Many models require normalization of the input data. If this is done using the average or maximum of the overall data set, then information from the test set will now be influencing the training set. For this reason, any normalization should be applied on a subset basis.\n",
    "\n",
    "Dimensionality reduction techniques such as PCA should be fit only on the training set. Then, to apply it to your test set, the transform method of PCA should be called (in the case of a scikit-learn model) on the test set. If instead, the pre-processor is fit on the entire dataset, information from the test set will be leaked, since the parameters of the pre-processing model will be fitted with knowledge of the test set. The same applies to transformation techniques such as TF-IDF vectorizers.\n",
    "\n",
    "If the Imputer for missing values is run before calling train_test_split. The data will leak subtly as the test data will be used for imputing the training data. The end result? The model will get outstanding validation scores, giving great confidence in it, but perform poorly when it is deployed to make decisions.\n",
    "\n",
    "*Leaky Predictors:* During feature engineering, any features updated (or created) after the target value is realized should be excluded. Because when we use this model to make new predictions,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-pepper",
   "metadata": {},
   "source": [
    "- **What does `time.time()` returns?**\n",
    "\n",
    "The current time in ms since midnight, January 1, 1970 GMT (the Unix time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closing-controversy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615324795.0802598"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-cocktail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-input",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-excitement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-victor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-disabled",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-shame",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opposite-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'aa', '_i2', '_i3', '_i4', '_i5', '_i6', '_6', '_i7', '_7', '_i8', '_i9', '_9', '_i10', '_10', '_i11', 'Date', 'date2', 'is_date', '_i12', '_12', '_i13', '_13', '_i14', '_14', '_i15', '_i16', '_i17', '_17', '_i18', '_i19', '_19', '_i20'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "endless-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'aa', '_i2', '_i3', '_i4', '_i5', '_i6', '_6', '_i7', '_7', '_i8', '_i9', '_9', '_i10', '_10', '_i11', 'Date', 'date2', 'is_date', '_i12', '_12', '_i13', '_13', '_i14', '_14', '_i15', '_i16', '_i17', '_17', '_i18', '_i19', '_19', '_i20', '_20', '_i21'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
