{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respective-irish",
   "metadata": {},
   "source": [
    "- **What is pickling/unpickling?**\n",
    "\n",
    "Python library offers a feature - serialization out of the box. Serializing a object refers to transforming it into a format that can be stored, so as to be able to deserialize it later on, to obtain the original object. Here, the pickle module comes into play.\n",
    "\n",
    "**Pickling** is the name of the serialization process in Python. Any object in Python can be serialized into a byte stream and dumped as a file in the memory. The process of pickling is compact but pickle objects can be compressed further. Moreover, pickle keeps track of the objects it has serialized and the serialization is portable across versions.\n",
    "The function used for the above process is `pickle.dump()`.\n",
    "\n",
    "**Unpickling** is the complete inverse of pickling. It deserializes the byte stream to recreate the objects stored in the file, and loads the object to memory.\n",
    "The function used for the above process is `pickle.load()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-medicine",
   "metadata": {},
   "source": [
    "- **What is `__dict__` method?**\n",
    "\n",
    "\n",
    "`__dict__` is A dictionary or other mapping object used to store an object’s (writable) attributes.\n",
    "Or speaking in simple words every object in python has an attribute which is denoted by `__dict__`.\n",
    "And this object contains all attributes defined for the object. `__dict__` is also called `mappingproxy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__repr__': <slot wrapper '__repr__' of 'bool' objects>,\n",
       "              '__and__': <slot wrapper '__and__' of 'bool' objects>,\n",
       "              '__rand__': <slot wrapper '__rand__' of 'bool' objects>,\n",
       "              '__xor__': <slot wrapper '__xor__' of 'bool' objects>,\n",
       "              '__rxor__': <slot wrapper '__rxor__' of 'bool' objects>,\n",
       "              '__or__': <slot wrapper '__or__' of 'bool' objects>,\n",
       "              '__ror__': <slot wrapper '__ror__' of 'bool' objects>,\n",
       "              '__new__': <function bool.__new__(*args, **kwargs)>,\n",
       "              '__doc__': 'bool(x) -> bool\\n\\nReturns True when the argument x is true, False otherwise.\\nThe builtins True and False are the only two instances of the class bool.\\nThe class bool is a subclass of the class int, and cannot be subclassed.'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-louis",
   "metadata": {},
   "source": [
    "- **What are** `*args` **and** `**kwargs` **?**\n",
    "\n",
    "Given a function defined as the following\n",
    "\n",
    "```\n",
    "def a_function(*args,**kwargs):\n",
    "    #some code\n",
    "```\n",
    "\n",
    "`args` is a tuple for the positional arguments, and `kwargs` a dictionary for the keyword arguments. * unpacks a tuple and ** a dictionary.\n",
    "`*args` (positional arguments) always comes before `**kwargs` (keyword arguments)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-working",
   "metadata": {},
   "source": [
    "- **What is `__init__.py` for in a Python source directory?** \n",
    "\n",
    "A regular package is typically implemented as a directory containing an `__init__.py` file. When a regular package is imported, this `__init__.py` file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The `__init__.py` file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.\n",
    "\n",
    "For example, the following file system layout defines a top level parent package with three subpackages:\n",
    "```\n",
    "parent/\n",
    "    __init__.py\n",
    "    one/\n",
    "        __init__.py\n",
    "    two/\n",
    "        __init__.py\n",
    "    three/\n",
    "        __init__.py\n",
    "```\n",
    "\n",
    "Importing `parent.one` will implicitly execute `parent/__init__.py` and `parent/one/__init__.py`. Subsequent imports of `parent.two` or `parent.three` will execute `parent/two/__init__.py` and `parent/three/__init__.py` respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-timing",
   "metadata": {},
   "source": [
    "\n",
    "- **Meaning of `@classmethod` and `@staticmethod` in python?**\n",
    "\n",
    "`@staticmethod` function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It’s definition is immutable via inheritance.\n",
    "\n",
    "`@classmethod` function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That’s because the first argument for `@classmethod` function must always be `cls` (class).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "patent-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Date(object):\n",
    "\n",
    "    def __init__(self, day=0, month=0, year=0):\n",
    "        self.day = day\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, date_as_string):\n",
    "        day, month, year = map(int, date_as_string.split('-'))\n",
    "        date1 = cls(day, month, year)\n",
    "        return date1\n",
    "\n",
    "    @staticmethod\n",
    "    def is_date_valid(date_as_string):\n",
    "        day, month, year = map(int, date_as_string.split('-'))\n",
    "        return day <= 31 and month <= 12 and year <= 3999\n",
    "\n",
    "date2 = Date.from_string('11-09-2012')\n",
    "is_date = Date.is_date_valid('11-09-2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "great-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Date at 0x201735174f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date2 = Date.from_string('11-09-2012')\n",
    "date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forced-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date.is_date_valid('11-09-2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-alliance",
   "metadata": {},
   "source": [
    "- **How can the ternary operators be used in python?**\n",
    "\n",
    "[on_true] if [expression] else [on_false]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-candidate",
   "metadata": {},
   "source": [
    "- **Data preprocessing before spliting in train/test samples is a good praxis?**\n",
    "\n",
    "We must be careful with **Data Leakage**, that is when information from outside the training dataset is used to create the model and hence can lead to predictions too optimistic.\n",
    "\n",
    "Many models require normalization of the input data. If this is done using the average or maximum of the overall data set, then information from the test set will now be influencing the training set. For this reason, any normalization should be applied on a subset basis.\n",
    "\n",
    "Dimensionality reduction techniques such as PCA should be fit only on the training set. Then, to apply it to your test set, the transform method of PCA should be called (in the case of a scikit-learn model) on the test set. If instead, the pre-processor is fit on the entire dataset, information from the test set will be leaked, since the parameters of the pre-processing model will be fitted with knowledge of the test set. The same applies to transformation techniques such as TF-IDF vectorizers.\n",
    "\n",
    "If the Imputer for missing values is run before calling train_test_split. The data will leak subtly as the test data will be used for imputing the training data. The end result? The model will get outstanding validation scores, giving great confidence in it, but perform poorly when it is deployed to make decisions.\n",
    "\n",
    "*Leaky Predictors:* During feature engineering, any features updated (or created) after the target value is realized should be excluded. Because when we use this model to make new predictions,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-pepper",
   "metadata": {},
   "source": [
    "- **What does `time.time()` returns?**\n",
    "\n",
    "The current time in ms since midnight, January 1, 1970 GMT (the Unix time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closing-controversy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615324795.0802598"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-arkansas",
   "metadata": {},
   "source": [
    "- **When is a number not itself?**\n",
    "\n",
    "The Python keyword `is` tests whether two variables refer to the exact same object, not just if they are equal. \n",
    "\n",
    "Python creates singletons for the most commonly used integers. One good reason to do this is that small numbers get used so frequently that if Python had to create a brand new object every time it needed a number, and then free the object when it goes out of scope, it would start to actually take a noticeable amount of time. 256 is a singleton while 257 is not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "necessary-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_num_1   = 1000\n",
    "big_num_2   = 1000\n",
    "small_num_1 = 2\n",
    "small_num_2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "executive-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_num_1 is big_num_2,small_num_1 is small_num_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-headquarters",
   "metadata": {},
   "source": [
    "-**Explain how a ROC curve works**\n",
    "\n",
    "\n",
    "The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).\n",
    "\n",
    "![roc](https://miro.medium.com/max/1175/1*2nd7NTEBosPakccmLVWy9A.png)\n",
    "\n",
    "The AUC is the area under the ROC curve and it represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s.\n",
    "\n",
    "(See https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-injury",
   "metadata": {},
   "source": [
    "- **Define precision and recall.**\n",
    "\n",
    "**Recall** is also known as the true positive rate: the amount of positives your model claims compared to the actual number of positives there are throughout the data. \n",
    "\n",
    "$$Recall=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "**Precision** is also known as the positive predictive value, and it is a measure of the amount of accurate positives your model claims compared to the number of positives it actually claims. \n",
    "$$Precision=\\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-victor",
   "metadata": {},
   "source": [
    "- **What is Bayes’ Theorem? How is it useful in a machine learning context?**\n",
    "\n",
    "Bayes’ Theorem gives you the posterior probability of an event given what is known as prior knowledge.\n",
    "\n",
    "Mathematically, it’s expressed as the true positive rate of a condition sample divided by the sum of the false positive rate of the population and the true positive rate of a condition. Say you had a 60% chance of actually having the flu after a flu test, but out of people who had the flu, the test will be false 50% of the time, and the overall population only has a 5% chance of having the flu. Would you actually have a 60% chance of having the flu after having a positive test?\n",
    "\n",
    "Bayes’ Theorem says no. It says that you have: \n",
    "\n",
    "(0.6 x 0.05) (TP Rate of a Condition Sample) / (0.6 x 0.05)(TP Rate of a Condition Sample) + (0.5 x 0.95) (FP Rate of a Population)  \n",
    "\n",
    "= 0.0594 or 5.94% chance of getting a flu.\n",
    "\n",
    "https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-contribution",
   "metadata": {},
   "source": [
    "- **Why is “Naive” Bayes naive?**\n",
    "\n",
    "\n",
    "Despite its practical applications, especially in text mining, Naive Bayes is considered “Naive” because it makes an assumption that is virtually impossible to see in real-life data: the conditional probability is calculated as the pure product of the individual probabilities of components. This implies the absolute independence of features — a condition probably never met in real life.\n",
    "\n",
    "As a Quora commenter put it whimsically, a Naive Bayes classifier that figured out that you liked pickles and ice cream would probably naively recommend you a pickle ice cream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-shelf",
   "metadata": {},
   "source": [
    "- **Explain the difference between L1 and L2 regularization.**\n",
    "\n",
    "**L2 (Ridge)** regularization tends to spread error among all the terms, while **L1 (Lasso)** is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-spouse",
   "metadata": {},
   "source": [
    "- **What’s the difference between Type I and Type II error?**\n",
    "\n",
    "Type I error is a false positive, while Type II error is a false negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-watershed",
   "metadata": {},
   "source": [
    "- **What is deep learning, and how does it contrast with other machine learning algorithms?**\n",
    "\n",
    "Deep learning is a subset of machine learning that is concerned with neural networks: how to use backpropagation and certain principles from neuroscience to more accurately model large sets of unlabelled or semi-structured data. In that sense, deep learning represents an unsupervised learning algorithm that learns representations of data through the use of neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-petersburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-disabled",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-shame",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opposite-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'aa', '_i2', '_i3', '_i4', '_i5', '_i6', '_6', '_i7', '_7', '_i8', '_i9', '_9', '_i10', '_10', '_i11', 'Date', 'date2', 'is_date', '_i12', '_12', '_i13', '_13', '_i14', '_14', '_i15', '_i16', '_i17', '_17', '_i18', '_i19', '_19', '_i20'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "endless-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'aa', '_i2', '_i3', '_i4', '_i5', '_i6', '_6', '_i7', '_7', '_i8', '_i9', '_9', '_i10', '_10', '_i11', 'Date', 'date2', 'is_date', '_i12', '_12', '_i13', '_13', '_i14', '_14', '_i15', '_i16', '_i17', '_17', '_i18', '_i19', '_19', '_i20', '_20', '_i21'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
